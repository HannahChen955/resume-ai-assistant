import os
import pdfplumber
import docx
import csv
from tqdm import tqdm
from dotenv import load_dotenv
import weaviate
import uuid
import openai
from datetime import datetime

# âœ… åŠ è½½ .env ç¯å¢ƒå˜é‡
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# âœ… åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
openai_client = openai.OpenAI(api_key=openai_api_key)

# âœ… åˆå§‹åŒ– Weaviate å®¢æˆ·ç«¯
client = weaviate.Client(
    url="http://weaviate:8080",
    additional_headers={"X-OpenAI-Api-Key": openai_api_key}
)

# âœ… å›ºå®šå‘½åç©ºé—´ï¼Œç¡®ä¿ UUID ä¸€è‡´
NAMESPACE = uuid.UUID("12345678-1234-5678-1234-567812345678")

# âœ… å„ç±»ç®€å†æ–‡ä»¶è§£æ
def parse_pdf(path):
    with pdfplumber.open(path) as pdf:
        return "\n".join([page.extract_text() or "" for page in pdf.pages])

def parse_docx(path):
    doc = docx.Document(path)
    return "\n".join([para.text for para in doc.paragraphs])

def parse_csv(path):
    try:
        with open(path, encoding="utf-8") as f:
            reader = csv.reader(f)
            rows = ["ã€".join(row) for row in reader]
            return "\n".join(rows)
    except Exception as e:
        print(f"âŒ CSV è§£æå¤±è´¥: {path}, é”™è¯¯: {e}")
        return ""

# âœ… ç¡®ä¿ Candidates é›†åˆå­˜åœ¨
def ensure_collection_exists():
    try:
        print("â³ å‡†å¤‡åˆ›å»º/æ›´æ–°é›†åˆ...")
        
        # âœ… å¼ºåˆ¶åˆ é™¤ç°æœ‰é›†åˆï¼ˆå¼€å‘ç¯å¢ƒä¸­æ–¹ä¾¿è°ƒè¯•ï¼‰
        try:
            if client.schema.exists("Candidates"):
                print("ğŸ—‘ï¸ åˆ é™¤ç°æœ‰é›†åˆ...")
                client.schema.delete_class("Candidates")
                print("âœ… ç°æœ‰é›†åˆå·²åˆ é™¤")
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤é›†åˆæ—¶å‡ºé”™ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {str(e)}")
        
        # âœ… åˆ›å»ºæ–°é›†åˆ
        class_obj = {
            "class": "Candidates",
            "vectorizer": "none",  # æ‰‹åŠ¨æä¾›å‘é‡ï¼Œç¦ç”¨è‡ªåŠ¨å‘é‡åŒ–
            "vectorIndexConfig": {  # å¿…é¡»è®¾ç½®ï¼Œå¦åˆ™å‘é‡ä¸ä¼šè¢«æŒä¹…åŒ–
                "distance": "cosine"  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            },
            "properties": [
                {
                    "name": "name",
                    "dataType": ["text"],  # ç»Ÿä¸€ä½¿ç”¨ text ç±»å‹
                    "description": "ç®€å†æ–‡ä»¶å"
                },
                {
                    "name": "summary",
                    "dataType": ["text"],
                    "description": "ç®€å†æ‘˜è¦ï¼ˆå‰300å­—ï¼‰"
                },
                {
                    "name": "content",
                    "dataType": ["text"],
                    "description": "ç®€å†å…¨æ–‡å†…å®¹"
                },
                {
                    "name": "file_type",
                    "dataType": ["text"],  # æ”¹ä¸º text
                    "description": "æ–‡ä»¶ç±»å‹ï¼ˆpdf/docxç­‰ï¼‰"
                },
                {
                    "name": "processed_at",
                    "dataType": ["text"],  # æ”¹ä¸º text
                    "description": "å¤„ç†æ—¶é—´æˆ³"
                }
            ]
        }
        
        client.schema.create_class(class_obj)
        print("âœ… æˆåŠŸåˆ›å»ºæ–°é›†åˆï¼Œé…ç½®å¦‚ä¸‹:")
        print(f"  - å‘é‡åŒ–æ–¹å¼: æ‰‹åŠ¨")
        print(f"  - å‘é‡ç´¢å¼•: å·²å¯ç”¨ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰")
        print(f"  - å­—æ®µæ•°é‡: {len(class_obj['properties'])}")
                
    except Exception as e:
        print(f"âŒ åˆ›å»º/æ›´æ–°é›†åˆå¤±è´¥:")
        print(f"  - é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
        raise e

# âœ… ä¸»å¤„ç†å‡½æ•°
def index_resumes(folder="data/resumes"):
    # é¦–å…ˆç¡®ä¿é›†åˆå­˜åœ¨
    ensure_collection_exists()
    
    os.makedirs(folder, exist_ok=True)
    file_list = os.listdir(folder)
    print(f"\nâœ… æ‰¾åˆ° {len(file_list)} ä¸ªç®€å†æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

    success_count = 0
    error_count = 0

    for filename in tqdm(file_list, desc="å¤„ç†ç®€å†"):
        path = os.path.join(folder, filename)
        try:
            # âœ… æ–‡ä»¶æ ¼å¼è§£æ
            if filename.endswith(".pdf"):
                text = parse_pdf(path)
            elif filename.endswith(".docx"):
                text = parse_docx(path)
            elif filename.endswith(".txt"):
                with open(path, encoding="utf-8") as f:
                    text = f.read()
            elif filename.endswith(".csv"):
                text = parse_csv(path)
            else:
                print(f"âŒ è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                error_count += 1
                continue

            text = text.strip().replace("\n", " ")
            if len(text) == 0:
                print(f"âš ï¸ æ–‡ä»¶ {filename} æå–æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                error_count += 1
                continue
            if len(text) > 8000:
                text = text[:8000]

            # âœ… æ‰‹åŠ¨ç”Ÿæˆå‘é‡
            try:
                embedding_response = openai_client.embeddings.create(
                    input=[text],
                    model="text-embedding-ada-002"
                )
                embedding = embedding_response.data[0].embedding
                print(f"\nâœ… å‘é‡ç”ŸæˆæˆåŠŸ: {filename}")
                print(f"  - ç»´åº¦: {len(embedding)}")
                print(f"  - æ–‡æœ¬é•¿åº¦: {len(text)}")
            except Exception as e:
                print(f"\nâŒ å‘é‡ç”Ÿæˆå¤±è´¥: {filename}")
                print(f"  - é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
                error_count += 1
                continue

            # âœ… ä¸ºè¯¥ç®€å†ç”Ÿæˆå›ºå®š UUIDï¼ˆç¡®ä¿æ›´æ–°/è¦†ç›–ï¼‰
            resume_uuid = str(uuid.uuid5(NAMESPACE, filename))

            # âœ… ä¸Šä¼ å‘é‡å¯¹è±¡ï¼ˆä½¿ç”¨å›ºå®š UUIDï¼‰
            properties = {
                "name": filename,
                "summary": text[:300],
                "content": text,
                "file_type": os.path.splitext(filename)[1][1:],
                "processed_at": datetime.now().isoformat()
            }

            # âœ… æ·»åŠ é”™è¯¯å¤„ç†
            try:
                # æ‰“å°å‘é‡ä¿¡æ¯ç”¨äºè°ƒè¯•
                print(f"\nâ³ å‡†å¤‡ä¸Šä¼ å‘é‡æ•°æ®:")
                print(f"  - å‘é‡ç±»å‹: {type(embedding)}")
                print(f"  - å‘é‡é•¿åº¦: {len(embedding)}")
                print(f"  - å‘é‡ç¤ºä¾‹: [{embedding[0]:.6f}, {embedding[1]:.6f}, ...]")
                
                # åˆ›å»ºæ–°å¯¹è±¡
                result = client.data_object.create(
                    data_object=properties,
                    class_name="Candidates",
                    uuid=resume_uuid,
                    vector=embedding
                )
                
                # éªŒè¯ä¸Šä¼ ç»“æœ
                print(f"\nâœ… Weaviate å“åº”:")
                print(f"  - çŠ¶æ€: {'æˆåŠŸ' if result else 'å¤±è´¥'}")
                print(f"  - UUID: {resume_uuid}")
                success_count += 1
            except Exception as e:
                print(f"âŒ ä¸Šä¼ å¤±è´¥: {filename}")
                print(f"  - é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
                if hasattr(e, 'response'):
                    print(f"  - å“åº”çŠ¶æ€: {e.response.status_code if hasattr(e.response, 'status_code') else 'unknown'}")
                    print(f"  - å“åº”å†…å®¹: {e.response.text if hasattr(e.response, 'text') else 'unknown'}")
                error_count += 1
                continue

        except Exception as e:
            print(f"\nâŒ å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™:")
            print(f"  - é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
            if hasattr(e, 'response'):
                print(f"  - å“åº”çŠ¶æ€: {e.response.status_code if hasattr(e.response, 'status_code') else 'unknown'}")
                print(f"  - å“åº”å†…å®¹: {e.response.text if hasattr(e.response, 'text') else 'unknown'}")
            error_count += 1

    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"  âœ… æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    print(f"  âŒ å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    print(f"  ğŸ“Š æˆåŠŸç‡: {success_count/(success_count+error_count)*100:.1f}%")

# âœ… è„šæœ¬å…¥å£
if __name__ == "__main__":
    index_resumes()
