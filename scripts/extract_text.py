#!/usr/bin/env python3

import os
import re
import fitz  # PyMuPDF
from docx import Document
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv
import json
import uuid
from pdf2image import convert_from_path
from PIL import Image
import pytesseract
from scripts.config import settings

# âœ… ç¯å¢ƒå˜é‡
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# âœ… è·¯å¾„é…ç½®
INPUT_DIR = "data/resumes"
OUTPUT_DIR = "data/resumes_extract_enhanced"
MODEL = "gpt-3.5-turbo-1106"

# âœ… é»‘åå•å…³é”®è¯
BLACKLIST = ["ä¸ªäººç®€å†", "çŒè˜", "BOSSç›´è˜", "å®¢æˆ·åç§°", "é¡¹ç›®åç§°", "original", "standard"]

# ========== å·¥å…·å‡½æ•° ==========

def extract_pdf_text(file_path):
    try:
        doc = fitz.open(file_path)
        return "\n".join([page.get_text() for page in doc])
    except Exception as e:
        print(f"âŒ PDFè¯»å–å¤±è´¥ï¼š{file_path} | {e}")
        return None

def extract_docx_text(file_path):
    try:
        doc = Document(file_path)
        return "\n".join([p.text for p in doc.paragraphs])
    except Exception as e:
        print(f"âŒ DOCXè¯»å–å¤±è´¥ï¼š{file_path} | {e}")
        return None

def extract_via_ocr(pdf_path):
    try:
        print(f"ğŸ“¸ å°è¯• OCR è¯†åˆ«ï¼š{os.path.basename(pdf_path)}")
        images = convert_from_path(pdf_path, dpi=300)
        if not images:
            return None
        return pytesseract.image_to_string(images[0], lang='chi_sim')
    except Exception as e:
        print(f"âš ï¸ OCR æå–å¤±è´¥ï¼š{e}")
        return None

def enhance_text(text):
    text = re.sub(r'(Confidential:|Disclaimer:|This report has been prepared).*?(executives concerned\.|verification\.)', '', text, flags=re.IGNORECASE | re.DOTALL)
    text = re.sub(r'\b[a-zA-Z0-9]{20,}\b', '', text)
    text = re.sub(r'(~{2,}|-{2,}|={2,}|\+{2,})', '', text)
    text = re.sub(r'\s{2,}', ' ', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()

def gpt_extract_fields(text):
    snippet = text[:600]
    prompt = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­è¯†åˆ«ä»¥ä¸‹å­—æ®µï¼ˆè‹¥ç¼ºå¤±è¯·å†™ nullï¼‰ï¼š
- å§“å
- åº”è˜èŒä½
- æ‰‹æœºå·
- é‚®ç®±
ä»…è¿”å›æ ‡å‡† JSONï¼Œä¸è¦é™„åŠ è¯´æ˜ã€‚

æ–‡æœ¬å¦‚ä¸‹ï¼š
\"\"\"
{snippet}
\"\"\"
    """
    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=300
        )
        content = response.choices[0].message.content.strip()
        content = re.sub(r"^```(json)?|```$", "", content)
        return json.loads(content) if content else {}
    except Exception as e:
        print(f"âš ï¸ GPTå­—æ®µæå–å¤±è´¥ï¼š{e}")
        return {}

def extract_name_fallback(filename, text):
    base = os.path.splitext(os.path.basename(filename))[0]
    name_candidates = re.findall(r'[\u4e00-\u9fa5]{2,4}', base)
    for name in name_candidates:
        if name not in BLACKLIST:
            return name
    head_text = text[:50]
    name_candidates = re.findall(r'[\u4e00-\u9fa5]{2,4}', head_text)
    for name in name_candidates:
        if name not in BLACKLIST:
            return name
    return "æœªçŸ¥å§“å"

def insert_header_block(text, fields):
    block = ["=" * 30]
    for key in ['å§“å', 'åº”è˜èŒä½', 'æ‰‹æœºå·', 'é‚®ç®±']:
        if fields.get(key):
            block.append(f"{key}ï¼š{fields[key]}")
    block.append("=" * 30)
    block.append("")
    return "\n".join(block) + text

def generate_filename(fields):
    name = fields.get("å§“å") or "æœªçŸ¥å§“å"
    position = fields.get("åº”è˜èŒä½") or "æœªçŸ¥èŒä½"
    for kw in BLACKLIST:
        name = name.replace(kw, "")
        position = position.replace(kw, "")
    name = re.sub(r"[^\u4e00-\u9fa5A-Za-z0-9]", "", name)
    position = re.sub(r"[^\u4e00-\u9fa5A-Za-z0-9]", "", position)
    uid = str(uuid.uuid4())[:8]
    return f"{name}_{position}_{uid}.txt"

# ========== ä¸»æµç¨‹ ==========

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.pdf', '.docx'))]
    success, fail = 0, 0

    for filename in tqdm(files, desc="Extracting with AI enhancement"):
        try:
            path = os.path.join(INPUT_DIR, filename)
            ext = filename.lower().split('.')[-1]

            text = None
            if ext == "pdf":
                text = extract_pdf_text(path)
                if not text or not text.strip():
                    print(f"âš ï¸ PyMuPDF æå–å¤±è´¥ï¼Œåˆ‡æ¢ OCRï¼š{filename}")
                    text = extract_via_ocr(path)
            elif ext == "docx":
                text = extract_docx_text(path)
            else:
                print(f"â­ï¸ è·³è¿‡ï¼šä¸æ”¯æŒçš„æ ¼å¼ {filename}")
                continue

            if not text or not text.strip():
                print(f"âš ï¸ ç©ºæ–‡æœ¬å ä½ï¼š{filename}")
                text = "[æ–‡ä»¶è¯»å–å¤±è´¥æˆ–å†…å®¹ä¸ºç©º]"

            text = enhance_text(text)
            fields = gpt_extract_fields(text) or {}

            # âœ… åªæœ‰å½“ GPT æ²¡æå–å‡ºå§“åæ—¶å† fallback
            if not fields.get("å§“å"):
                fields["å§“å"] = extract_name_fallback(filename, text)

            output_text = insert_header_block(text, fields)
            output_name = generate_filename(fields)
            output_path = os.path.join(OUTPUT_DIR, output_name)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write(output_text)
            print(f"âœ… è¾“å‡ºï¼š{output_name}")
            success += 1

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{filename} | {e}")
            fail += 1

    print(f"\nğŸ¯ å®Œæˆï¼šå…± {len(files)} ä»½ | æˆåŠŸï¼š{success} | å¤±è´¥ï¼š{fail}")

if __name__ == "__main__":
    main()
