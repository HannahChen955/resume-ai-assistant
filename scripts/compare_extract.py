#!/usr/bin/env python3

"""
å¯¹æ¯”åŸå§‹ç®€å†ä¸æå–åçš„ç®€å†å†…å®¹ï¼ˆè¯­ä¹‰ + å…³é”®ä¿¡æ¯å­—æ®µï¼‰
è¾“å‡º Markdown æŠ¥å‘Šï¼Œè¯„ä¼°æå–è´¨é‡ã€‚
"""

import os
import re
import difflib
import json
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# æ–‡ä»¶è·¯å¾„
BEFORE_DIR = "data/resumes"
AFTER_DIR = "data/resumes_extract_enhanced"
REPORT_PATH = "extract_compare_report.md"

# åˆ¤æ–­ç›¸ä¼¼åº¦
def get_similarity_score(text1, text2) -> float:
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{
                "role": "user",
                "content": f"""è¯·ä½ åˆ¤æ–­ä¸‹é¢ä¸¤ä¸ªæ–‡æœ¬æ˜¯å¦å±äºåŒä¸€ä¸ªäººçš„ç®€å†ï¼Œåªè¿”å›ä¸€ä¸ª 0-100 çš„åˆ†æ•°ï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šå¯èƒ½æ˜¯ï¼š
ã€ç®€å†åŸå§‹ç‰ˆã€‘ï¼š
{text1}

ã€ç®€å†æå–åã€‘ï¼š
{text2}
"""
            }],
            temperature=0
        )
        score_text = response.choices[0].message.content.strip()
        score = float(re.findall(r"\d+", score_text)[0])
        return min(score, 100.0)
    except Exception as e:
        print("âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥:", e)
        return 0.0

# è¯»å–æ–‡ä»¶å†…å®¹
def read_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except:
        return ""

# æå–å­—æ®µ
def extract_fields(text: str):
    try:
        fields = {
            "å§“å": None,
            "èŒä½": None,
            "é‚®ç®±": None,
            "ç”µè¯": None
        }
        if match := re.search(r"å§“å[:ï¼š]?\s*(\S{1,6})", text):
            fields["å§“å"] = match.group(1)
        if match := re.search(r"æ„å‘èŒä½[:ï¼š]?\s*(\S{2,20})", text):
            fields["èŒä½"] = match.group(1)
        if match := re.search(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+", text):
            fields["é‚®ç®±"] = match.group(0)
        if match := re.search(r"(?:\+86[- ]?)?1[3-9]\d{9}", text):
            fields["ç”µè¯"] = match.group(0)
        return fields
    except:
        return {}

# æŸ¥æ‰¾æœ€åŒ¹é…çš„ after æ–‡ä»¶
def find_best_match(before_text: str, after_texts: dict):
    scores = {
        path: get_similarity_score(before_text, after_text)
        for path, after_text in after_texts.items()
    }
    best_path = max(scores, key=scores.get)
    return best_path, scores[best_path]

# ä¸»æµç¨‹
def run_compare():
    before_files = [f for f in os.listdir(BEFORE_DIR) if f.lower().endswith((".pdf", ".doc", ".docx", ".txt"))]
    after_files = [f for f in os.listdir(AFTER_DIR) if f.endswith(".txt")]

    after_texts = {
        f: read_file(os.path.join(AFTER_DIR, f)) for f in after_files
    }

    report_lines = ["# âœ… ç®€å†æŠ½å–æ¯”å¯¹æŠ¥å‘Š\n"]

    for bf in tqdm(before_files):
        before_path = os.path.join(BEFORE_DIR, bf)
        before_text = read_file(before_path)

        best_after, score = find_best_match(before_text, after_texts)
        after_text = after_texts[best_after]
        fields = extract_fields(after_text)

        if not isinstance(fields, dict):
            fields = {}

        missing = [k for k, v in fields.items() if not v or v == "null"]

        report_lines.append(f"## ğŸ“„ {bf}")
        report_lines.append(f"- åŒ¹é… After æ–‡ä»¶: `{best_after}`")
        report_lines.append(f"- ç›¸ä¼¼åº¦åˆ†æ•°: **{score:.1f}**")
        report_lines.append(f"- æŠ½å–å­—æ®µ: {json.dumps(fields, ensure_ascii=False)}")
        report_lines.append(f"- â—ç¼ºå¤±å­—æ®µ: {', '.join(missing) if missing else 'æ— '}")
        report_lines.append("")

    with open(REPORT_PATH, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))

    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{REPORT_PATH}")

if __name__ == "__main__":
    run_compare()