#!/usr/bin/env python3

import os
import sys
import uuid
import time
import json
import requests
from typing import List
import re
import pdfplumber
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv

# âœ… åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# âœ… ç¯å¢ƒå˜é‡é…ç½®
RESUMES_DIR = os.getenv("EXTRACTED_DIR", "data/resumes_extract_enhanced")
WEAVIATE_URL = os.getenv("WEAVIATE_URL", "http://localhost:8080")
WEAVIATE_CLASS = os.getenv("WEAVIATE_COLLECTION", "Candidates")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")
NAMESPACE_UUID = uuid.UUID("12345678-1234-5678-1234-567812345678")
TOP_N = 5
MAX_CHUNK_LENGTH = 300

# âœ… åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… è·å–å‘é‡
def get_embedding(text: str) -> List[float]:
    response = openai_client.embeddings.create(
        input=[text],
        model=EMBEDDING_MODEL
    )
    return response.data[0].embedding

# âœ… GPT åˆ†æ®µæ‰“åˆ†
def score_chunk(query: str, chunk: str) -> float:
    prompt = f"è¯·æ ¹æ®ä¸ {query} å²—ä½çš„ç›¸å…³æ€§ï¼Œå¯¹ä»¥ä¸‹æ–‡æœ¬æ‰“åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰ï¼Œåªè¿”å›æ•°å­—ï¼š\n\n{chunk}"
    response = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    try:
        return float(response.choices[0].message.content.strip().split()[0])
    except:
        return 0.0

# âœ… åˆ‡åˆ†æ–‡æœ¬æ®µè½
def chunk_text(text: str, max_length: int) -> List[str]:
    sentences = re.split(r'[\nã€‚ï¼ï¼Ÿ!ï¼Ÿ]', text)
    chunks, current = [], ""
    for sentence in sentences:
        if len(current) + len(sentence) < max_length:
            current += sentence + "ã€‚"
        else:
            if current:
                chunks.append(current.strip())
            current = sentence + "ã€‚"
    if current:
        chunks.append(current.strip())
    return [c for c in chunks if len(c) > 10]

# âœ… è¯»å–ç®€å†æ–‡æœ¬
def load_resume_text(file_path: str) -> str:
    if file_path.endswith(".txt"):
        with open(file_path, 'r', encoding="utf-8") as f:
            return f.read()
    return ""

# âœ… æ£€æŸ¥ Weaviate æ˜¯å¦å·²æœ‰è¯¥å¯¹è±¡
def object_exists(resume_uuid: str) -> bool:
    url = f"{WEAVIATE_URL}/v1/objects/{WEAVIATE_CLASS}/{resume_uuid}"
    response = requests.get(url)
    return response.status_code == 200

# âœ… ä¸Šä¼ åˆ° Weaviate
def upload_resume(filename: str, content: str, vector: List[float], resume_uuid: str):
    payload = {
        "class": WEAVIATE_CLASS,
        "id": resume_uuid,
        "properties": {
            "filename": filename,
            "content": content,
            "notes": []  # âœ… åˆå§‹åŒ– notes å­—æ®µ
        },
        "vector": vector
    }
    url = f"{WEAVIATE_URL}/v1/objects"
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        print(f"âœ… æ’å…¥æˆåŠŸ: {filename}")
    else:
        print(f"âŒ æ’å…¥å¤±è´¥: {filename}")
        print("çŠ¶æ€ç :", response.status_code)
        try:
            print("é”™è¯¯ä¿¡æ¯:", response.json())
        except:
            print("âš ï¸ å“åº”ä½“è§£æå¤±è´¥")

# âœ… ä¸»é€»è¾‘
def index_resumes_topn():
    if not os.path.exists(RESUMES_DIR):
        print(f"âŒ ç®€å†ç›®å½•ä¸å­˜åœ¨: {RESUMES_DIR}")
        return

    files = [f for f in os.listdir(RESUMES_DIR) if f.endswith(".txt")]
    if not files:
        print("âš ï¸ æ²¡æœ‰å‘ç°ç®€å†æ–‡ä»¶")
        return

    print("ğŸ“„ å¼€å§‹å¤„ç†ç®€å†:")

    for filename in tqdm(files):
        file_path = os.path.join(RESUMES_DIR, filename)
        full_text = load_resume_text(file_path)
        if not full_text.strip():
            print(f"âš ï¸ è·³è¿‡ç©ºæ–‡ä»¶: {filename}")
            continue

        chunks = chunk_text(full_text, MAX_CHUNK_LENGTH)
        scored = [(chunk, score_chunk("å…‰å­¦å·¥ç¨‹å¸ˆ", chunk)) for chunk in chunks]
        sorted_chunks = sorted(scored, key=lambda x: x[1], reverse=True)
        selected_chunks = [chunk for chunk, _ in sorted_chunks[:TOP_N]]

        if not selected_chunks:
            print(f"âš ï¸ æ— æœ‰æ•ˆæ®µè½: {filename}")
            continue

        final_text = "\n".join(selected_chunks)
        resume_uuid = str(uuid.uuid5(NAMESPACE_UUID, filename))

        if object_exists(resume_uuid):
            print(f"â© å·²å­˜åœ¨: {filename}")
            continue

        try:
            vector = get_embedding(final_text)
            upload_resume(filename, final_text, vector, resume_uuid)
            time.sleep(0.3)
        except Exception as e:
            import traceback
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {filename}")
            traceback.print_exc()

    print("âœ… æ‰€æœ‰ç®€å†å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    index_resumes_topn()
