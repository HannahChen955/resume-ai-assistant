#!/usr/bin/env python3
"""
ç®€åŽ†æœç´¢ç³»ç»Ÿï¼ˆREST APIç‰ˆï¼‰æ”¯æŒ OpenAI / é€šä¹‰åƒé—® / DeepSeek
"""

import os
import sys
import json
import re
import time
import logging
import requests
from pathlib import Path
from typing import List, Dict, Any, Tuple
from functools import lru_cache
from dotenv import load_dotenv

# âœ… åŠ è½½ .env
load_dotenv()

# âœ… çŽ¯å¢ƒå˜é‡
WEAVIATE_URL = os.getenv("WEAVIATE_URL", "http://localhost:8080")
WEAVIATE_CLASS = os.getenv("WEAVIATE_COLLECTION", "Candidates")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002")
TOP_K = int(os.getenv("DEFAULT_TOP_K", "5"))
CERTAINTY = float(os.getenv("SEARCH_CERTAINTY", "0.75"))
SUMMARY_LENGTH = int(os.getenv("SUMMARY_LENGTH", "200"))
EMBEDDING_CACHE_SIZE = int(os.getenv("EMBEDDING_CACHE_SIZE", "100"))

# âœ… æ—¥å¿—è®¾ç½®
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# âœ… OpenAI Client
from openai import OpenAI
openai_client = OpenAI(api_key=OPENAI_API_KEY)

def is_uuid_like(s: str) -> bool:
    return re.match(r"^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$", s) is not None

class ResumeSearcher:
    def __init__(self, weaviate_url, weaviate_class, openai_client, embedding_model):
        self.weaviate_url = weaviate_url
        self.weaviate_class = weaviate_class
        self.openai_client = openai_client
        self.embedding_model = embedding_model
        print(f"ðŸ”§ å½“å‰ä½¿ç”¨ OpenAI æ¨¡åž‹: {self.embedding_model}")
        logger.info("ðŸ” åˆå§‹åŒ– ResumeSearcher")

    @staticmethod
    def format_summary(content: str) -> str:
        if not content:
            return ""
        summary = re.sub(r'\s+', ' ', content.strip())[:SUMMARY_LENGTH]
        return summary + "..." if len(content) > SUMMARY_LENGTH else summary

    @staticmethod
    def parse_filename(filename: str) -> Tuple[str, str]:
        name, job_title = "ï¼ˆæœªæå–ï¼‰", "ï¼ˆæœªæå–ï¼‰"
        match = re.match(r'(.+?)_(.+?)_', filename)
        if match:
            name = match.group(1)
            job_title = match.group(2)
        return name, job_title

    @lru_cache(maxsize=EMBEDDING_CACHE_SIZE)
    def get_embedding(self, text: str) -> List[float]:
        try:
            response = self.openai_client.embeddings.create(
                input=[text],
                model=self.embedding_model
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ èŽ·å–å‘é‡å¤±è´¥: {e}")
            raise

    def search(self, query: str) -> Dict[str, Any]:
        start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")

        try:
            # âœ… å¦‚æžœæ˜¯ UUID ç›´æŽ¥ç”¨ REST API æŸ¥è¯¢
            if is_uuid_like(query):
                logger.info("âš¡ï¸ æ£€æµ‹ä¸º UUIDï¼Œæ‰§è¡Œç²¾ç¡®æŸ¥æ‰¾")
                url = f"{self.weaviate_url}/v1/objects/{self.weaviate_class}/{query}"
                res = requests.get(url)
                if res.status_code == 200:
                    obj = res.json().get("properties", {})
                    name, job_title = self.parse_filename(obj.get("filename", ""))
                    elapsed = time.time() - start_time
                    return {
                        "æŸ¥è¯¢": query,
                        "å€™é€‰äººæ•°é‡": 1,
                        "å¤„ç†æ—¶é—´": f"{elapsed:.2f}ç§’",
                        "å€™é€‰äººåˆ—è¡¨": [{
                            "UUID": query,
                            "å§“å": name,
                            "åº”è˜èŒä½": job_title,
                            "æ–‡ä»¶å": obj.get("filename", ""),
                            "åŒ¹é…åº¦": "100.0%",
                            "ç®€åŽ†æ‘˜è¦": self.format_summary(obj.get("content", "")),
                            "æ²Ÿé€šè®°å½•": obj.get("notes", []),
                            "ç®€åŽ†å†…å®¹": obj.get("content", ""),
                        }]
                    }
                else:
                    return {"æŸ¥è¯¢": query, "å€™é€‰äººæ•°é‡": 0, "å€™é€‰äººåˆ—è¡¨": []}

            # âœ… å¦åˆ™æ‰§è¡Œå‘é‡æœç´¢
            embedding = self.get_embedding(query)
            graphql_query = {
                "query": f"""
                {{
                  Get {{
                    {self.weaviate_class}(
                      nearVector: {{
                        vector: {json.dumps(embedding)},
                        certainty: {CERTAINTY}
                      }},
                      limit: {TOP_K}
                    ) {{
                      filename
                      content
                      notes
                      _additional {{
                        id
                        distance
                      }}
                    }}
                  }}
                }}
                """
            }

            res = requests.post(f"{self.weaviate_url}/v1/graphql", json=graphql_query)
            if res.status_code != 200:
                raise Exception(f"GraphQL è¯·æ±‚å¤±è´¥ï¼š{res.status_code} - {res.text}")

            results = res.json()["data"]["Get"][self.weaviate_class]
            candidates = []
            for obj in results:
                content = obj.get("content", "")
                filename = obj.get("filename", "")
                notes = obj.get("notes", [])
                additional = obj.get("_additional", {})
                distance = additional.get("distance", 1.0)
                certainty = (1 - float(distance)) * 100

                name, job_title = self.parse_filename(filename)
                candidates.append({
                    "UUID": additional.get("id", "æœªçŸ¥"),
                    "å§“å": name,
                    "åº”è˜èŒä½": job_title,
                    "æ–‡ä»¶å": filename,
                    "åŒ¹é…åº¦": f"{certainty:.1f}%",
                    "ç®€åŽ†æ‘˜è¦": self.format_summary(content),
                    "æ²Ÿé€šè®°å½•": notes if notes else [],
                    "ç®€åŽ†å†…å®¹": content,
                })

            candidates.sort(key=lambda x: float(x["åŒ¹é…åº¦"].rstrip("%")), reverse=True)
            elapsed = time.time() - start_time

            return {
                "æŸ¥è¯¢": query,
                "å€™é€‰äººæ•°é‡": len(candidates),
                "å¤„ç†æ—¶é—´": f"{elapsed:.2f}ç§’",
                "å€™é€‰äººåˆ—è¡¨": candidates
            }

        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

def main():
    query = ""
    if len(sys.argv) > 1:
        for i in range(1, len(sys.argv)):
            if sys.argv[i] in ["--query", "-q", "--keywords", "-k"] and i + 1 < len(sys.argv):
                query = sys.argv[i + 1].strip()
                break
            elif i == 1:
                query = sys.argv[1].strip()

    if not query:
        print(json.dumps({"å€™é€‰äººåˆ—è¡¨": [], "æŸ¥è¯¢å…³é”®è¯": "", "çŠ¶æ€": "æ— å…³é”®è¯"}, ensure_ascii=False))
        return

    print(f"æœç´¢å…³é”®è¯: {query}")
    try:
        searcher = ResumeSearcher(WEAVIATE_URL, WEAVIATE_CLASS, openai_client, EMBEDDING_MODEL)
        result = searcher.search(query)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(json.dumps({
            "å€™é€‰äººåˆ—è¡¨": [],
            "æŸ¥è¯¢å…³é”®è¯": query,
            "çŠ¶æ€": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
        }, ensure_ascii=False))

if __name__ == "__main__":
    main()