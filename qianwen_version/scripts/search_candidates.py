#!/usr/bin/env python3

import sys
import json
import os
import re
import time
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from functools import lru_cache
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
root_dir = str(Path(__file__).parent.parent)
if root_dir not in sys.path:
    sys.path.append(root_dir)

from dotenv import load_dotenv
from dashscope import Embedding
import dashscope

from scripts.weaviate_utils import (
    get_weaviate_client, WEAVIATE_CLASS_NAME, TOP_K_RESULTS
)
from scripts.config import Config
from weaviate.classes.query import MetadataQuery

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format=Config.LOG_FORMAT
)
logger = logging.getLogger(__name__)

# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv()
QIANWEN_API_KEY = os.getenv("DASHSCOPE_API_KEY")
dashscope.api_key = QIANWEN_API_KEY


class ResumeSearcher:
    def __init__(self):
        if not QIANWEN_API_KEY:
            raise ValueError("æœªæ‰¾åˆ° QIANWEN_API_KEY æˆ– DASHSCOPE_API_KEY çŽ¯å¢ƒå˜é‡")

        self.weaviate_client = None
        self.collection = None

    def connect(self) -> None:
        try:
            self.weaviate_client = get_weaviate_client(api_key=QIANWEN_API_KEY)
            self.weaviate_client.connect()
            self.collection = self.weaviate_client.collections.get(WEAVIATE_CLASS_NAME)
            logger.info("âœ… æˆåŠŸè¿žæŽ¥ Weaviate")
        except Exception as e:
            logger.error(f"âŒ è¿žæŽ¥ Weaviate å¤±è´¥: {e}")
            raise

    def disconnect(self) -> None:
        if self.weaviate_client and self.weaviate_client.is_ready():
            try:
                self.weaviate_client.close()
                logger.info("ðŸ”Œ å·²æ–­å¼€ Weaviate")
            except Exception as e:
                logger.warning(f"âš ï¸ æ–­å¼€é”™è¯¯: {e}")

    @staticmethod
    def format_summary(content: str) -> str:
        if not content:
            return ""
        summary = re.sub(r'\s+', ' ', content.strip())[:Config.SUMMARY_LENGTH]
        return summary + "..." if len(content) > Config.SUMMARY_LENGTH else summary

    @staticmethod
    def check_keywords(content: str) -> List[str]:
        if not content:
            return []
        content_lower = content.lower()
        return [k for k, v in Config.FILTER_KEYWORDS.items() 
                if any(kw.lower() in content_lower for kw in v)]

    @staticmethod
    def parse_filename(filename: str) -> Tuple[str, str]:
        name, job_title = "ï¼ˆæœªæå–ï¼‰", "ï¼ˆæœªæå–ï¼‰"
        match = re.match(r'(.+?)_(.+?)_', filename)
        if match:
            name = match.group(1)
            job_title = match.group(2)
        return name, job_title

    @staticmethod
    def evaluate_resume_quality(content: str) -> float:
        if not content:
            return 0.0
        score = 0.0
        length_score = min(len(content) / 2000, 1.0) * 0.3
        structure_score = 0.0
        if "æ•™è‚²èƒŒæ™¯" in content or "æ•™è‚²ç»åŽ†" in content:
            structure_score += 0.1
        if "å·¥ä½œç»éªŒ" in content or "å·¥ä½œç»åŽ†" in content:
            structure_score += 0.1
        if "é¡¹ç›®ç»éªŒ" in content or "é¡¹ç›®ç»åŽ†" in content:
            structure_score += 0.1
        if "æŠ€èƒ½" in content or "ä¸“ä¸šæŠ€èƒ½" in content:
            structure_score += 0.1
        info_score = 0.0
        if re.search(r'1[3-9]\d{9}', content):
            info_score += 0.1
        if re.search(r'[\w\.-]+@[\w\.-]+', content):
            info_score += 0.1
        if re.search(r'(æœ¬ç§‘|ç¡•å£«|åšå£«|MBA|PhD)', content):
            info_score += 0.1
        return length_score + structure_score + info_score

    @lru_cache(maxsize=Config.EMBEDDING_CACHE_SIZE)
    def get_embedding(self, text: str) -> List[float]:
        try:
            response = Embedding.call(
                model="text-embedding-v1",
                input=text
            )
            return response["output"]["embeddings"][0]["embedding"]
        except Exception as e:
            logger.error(f"âŒ å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def score_candidate(self, candidate: Dict[str, Any], query_keywords: Dict[str, Dict[str, float]]) -> float:
        vector_score = float(candidate["åŒ¹é…åº¦"].rstrip("%")) / 100.0
        keyword_score = 0.0
        content_lower = candidate["ç®€åŽ†å†…å®¹"].lower()

        essential_matches = []
        if "å¿…è¦è¯" in query_keywords:
            for word, weight in query_keywords["å¿…è¦è¯"].items():
                if word.lower() in content_lower:
                    essential_matches.append((word, weight))
                    keyword_score += weight

        bonus_matches = []
        if "åŠ åˆ†è¯" in query_keywords:
            for word, weight in query_keywords["åŠ åˆ†è¯"].items():
                if word.lower() in content_lower:
                    bonus_matches.append((word, weight))
                    keyword_score += weight

        max_possible_score = sum(query_keywords.get("å¿…è¦è¯", {}).values()) + \
                             sum(query_keywords.get("åŠ åˆ†è¯", {}).values())
        keyword_score = keyword_score / max_possible_score if max_possible_score > 0 else 0

        quality_score = self.evaluate_resume_quality(candidate["ç®€åŽ†å†…å®¹"])

        candidate["åŒ¹é…å…³é”®è¯"] = {
            "å¿…è¦è¯": [{"å…³é”®è¯": word, "æƒé‡": weight} for word, weight in essential_matches],
            "åŠ åˆ†è¯": [{"å…³é”®è¯": word, "æƒé‡": weight} for word, weight in bonus_matches]
        }

        total_score = (
            vector_score * Config.WEIGHTS["VECTOR_MATCH"] +
            keyword_score * Config.WEIGHTS["KEYWORD_MATCH"] +
            quality_score * Config.WEIGHTS["RESUME_QUALITY"]
        )
        return total_score

    def search(self, query: str) -> Dict[str, Any]:
        start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")

        try:
            query_keywords = Config.FILTER_KEYWORDS.get(query, {})
            logger.info(f"æŸ¥è¯¢å…³é”®è¯: {query_keywords}")

            embedding = self.get_embedding(query)
            logger.info(f"âœ… æŸ¥è¯¢å‘é‡ç”Ÿæˆå®Œæˆï¼Œç»´åº¦: {len(embedding)}")

            response = self.collection.query.near_vector(
                near_vector=embedding,
                target_vector="default",
                limit=TOP_K_RESULTS,
                return_metadata=["distance"]
            )

            candidates = []
            for obj in response.objects:
                distance = obj.metadata.distance
                if distance is None:
                    continue

                certainty = (1 - float(distance)) * 100
                content = obj.properties.get("content", "")
                filename = obj.properties.get("filename", "")
                name, job_title = self.parse_filename(filename)

                candidate = {
                    "UUID": str(obj.uuid),
                    "å§“å": name,
                    "åº”è˜èŒä½": job_title,
                    "æ–‡ä»¶å": filename,
                    "åŒ¹é…åº¦": f"{certainty:.1f}%",
                    "ç®€åŽ†æ‘˜è¦": self.format_summary(content),
                    "ç®€åŽ†å†…å®¹": content,
                }

                candidate["ç»¼åˆå¾—åˆ†"] = self.score_candidate(candidate, query_keywords)
                candidates.append(candidate)

            candidates.sort(key=lambda x: x["ç»¼åˆå¾—åˆ†"], reverse=True)
            search_time = time.time() - start_time

            return {
                "æŸ¥è¯¢": query,
                "å€™é€‰äººæ•°é‡": len(candidates),
                "å…³é”®è¯é…ç½®": {
                    "å¿…è¦è¯æ•°é‡": len(query_keywords.get("å¿…è¦è¯", {})),
                    "åŠ åˆ†è¯æ•°é‡": len(query_keywords.get("åŠ åˆ†è¯", {}))
                },
                "å¤„ç†æ—¶é—´": f"{search_time:.2f}ç§’",
                "å€™é€‰äººåˆ—è¡¨": candidates
            }

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            raise

def main():
    query = ""
    if len(sys.argv) > 1:
        for i in range(1, len(sys.argv)):
            if sys.argv[i] in ["--query", "-q"] and i + 1 < len(sys.argv):
                query = sys.argv[i + 1].strip()
                break
            elif sys.argv[i] not in ["--query", "-q"]:
                query = sys.argv[i].strip()
                break

    if not query:
        print(json.dumps({"å€™é€‰äººåˆ—è¡¨": [], "æŸ¥è¯¢å…³é”®è¯": "", "çŠ¶æ€": "æ— å…³é”®è¯"}, ensure_ascii=False))
        return

    print(f"æœç´¢å…³é”®è¯: {query}")
    try:
        searcher = ResumeSearcher()
        searcher.connect()
        result = searcher.search(query)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        print(json.dumps({
            "å€™é€‰äººåˆ—è¡¨": [],
            "æŸ¥è¯¢å…³é”®è¯": query,
            "çŠ¶æ€": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
        }, ensure_ascii=False))
    finally:
        if searcher:
            searcher.disconnect()

if __name__ == "__main__":
    main()